{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"blue\">\n",
    "Aggregation and Grouping\n",
    "</font>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<bold><i><font color = \"green\"> Here we will use the Planets dataset, available via the Seaborn package (see Visualization With Seaborn). \n",
    "It gives information on planets that astronomers have discovered around other stars (known as extrasolar planets or exoplanets for short). \n",
    "It can be downloaded with a simple Seaborn command </font></i></bold>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    " Simple Aggregation in Pandas.For series,output of aggregation is a single value   \n",
    "    </font> </i></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "ser = pd.Series(rng.rand(5))\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sum is\",ser.sum())\n",
    "print(\"mean is\",ser.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "  For a DataFrame, by default the aggregates return results within each column:\n",
    "    </font> </i></h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': rng.rand(5),\n",
    "                   'B': rng.rand(5)})\n",
    "print(df)\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "  If you need mean according to row wise\n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.mean(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<font color = \"purple\"> \n",
    "  There is a convenience method describe() that computes several common aggregates for each column and returns the result </font>\n",
    " </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.dropna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color = \"green\">\n",
    "The following summarizes some other built-in Pandas aggregations:</font>  </h3>\n",
    "<p></p>\n",
    "<font color=\"purple\">\n",
    "<p>1.count() -\tTotal number of items</p>\n",
    "<p>2.first(), last()  -\tFirst and last item</p>\n",
    "<p>3.mean(), median()\t- Mean and median</p>\n",
    "<p>4.min(), max()     -\tMinimum and maximum</p>\n",
    "<p>5.std(), var()\t    - Standard deviation and variance</p>\n",
    "<p>6.mad()            -\tMean absolute deviation</p>\n",
    "<p>7.prod()           -\tProduct of all items</p>\n",
    "<p>8.sum()            -\tSum of all items</p></font>\n",
    "<h3>These are all methods of DataFrame and Series objects.</h3> \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "GroupBy: Split, Apply, Combine\n",
    "often we would prefer to aggregate conditionally on some label or index: \n",
    "this is implemented in the so-called groupby operation\n",
    "  \n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split, apply, combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data': range(6)}, columns=['key', 'data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_obj =df.groupby('key')\n",
    "#What is the data type of grouped obj??\n",
    "print(type(grouped_obj))\n",
    "\n",
    "#what is the data type of x here??\n",
    "print(df.apply(lambda x : print(type(x))))\n",
    "\n",
    "\n",
    "grouped_obj.apply(lambda x: print(type(x)))\n",
    "df.groupby('key').sum()\n",
    "#you can apply any aggregation method on groupby(ex : min,max,mean etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    " Column indexing:\n",
    "The GroupBy object supports column indexing in the same way as the DataFrame, and returns a modified GroupBy object. For example\n",
    "    </font> </i></h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(planets.groupby('method'))\n",
    "print(planets.groupby('method')['orbital_period'])\n",
    "#Here we've selected a particular Series group from the original DataFrame group by reference to its column name. \n",
    "#As with the GroupBy object, no computation is done until we call some aggregate on the object:\n",
    "planets.groupby('method')['orbital_period'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><i><font color = \"green\">\n",
    "Iteration over groups:\n",
    "The GroupBy object supports direct iteration over the groups, returning each group as a Series or DataFrame:\n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for (method, group) in planets.groupby('method'):\n",
    "    print(\"{0:30s} shape={1}\".format(method, group.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Dispatch method</h3>\n",
    "<i><font color = \"green\">\n",
    "Through some Python class magic, any method not explicitly implemented by the GroupBy object will be passed through \n",
    "and called on the groups, whether they are DataFrame or Series objects. For example, you can use the describe() method\n",
    "of DataFrames to perform a set of aggregations that describe each group in the data:\n",
    "  \n",
    " </font> </i>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.groupby('method')['year'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    " Aggregate, filter, transform, apply :\n",
    "    </font> </i></h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                   'data1': range(6),\n",
    "                   'data2': rng.randint(0, 10, 6)},\n",
    "                   columns = ['key', 'data1', 'data2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "  Aggregation\n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate(['min', np.median, max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate({'data1': 'min',\n",
    "                             'data2': 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "Filtering:\n",
    "A filtering operation allows you to drop data based on the group properties \n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x['data2'].std() > 4\n",
    "\n",
    "print(df)\n",
    "print(df.groupby('key').std())\n",
    "print(df.groupby('key').filter(filter_func))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  \n",
    " \n",
    "<h3>Transformation:</h3>\n",
    "<i><font color = \"green\">\n",
    "While aggregation must return a reduced version of the data, transformation can return some transformed version of the \n",
    "full data to recombine. For such a transformation, the output is the same shape as the input. \n",
    "A common example is to center the data by subtracting the group-wise mean:\n",
    "</font> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "The apply() method---\n",
    "lets you apply an arbitrary function to the group results\n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_by_data2(x):\n",
    "    # x is a DataFrame of group values\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x\n",
    "\n",
    "df.groupby('key').apply(norm_by_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><i><font color = \"green\">\n",
    "A dictionary or series mapping index to group\n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('key')\n",
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "print(df2)\n",
    "print(df2.groupby(mapping).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "Any Python function:\n",
    "Further, any of the preceding key choices can be combined to group on a multi-index \n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)\n",
    "print(df2.groupby(str.lower).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">\n",
    "  A list of valid keys\n",
    "    </font> </i></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby([str.lower, mapping]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <font color = 'red'>Grouping example  </font></h2>\n",
    "\n",
    "As an example of this, in a couple lines of Python code we can put all these together and count discovered planets\n",
    "by method and by decade:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade = 10 * (planets['year'] // 10)\n",
    "decade = decade.astype(str) + 's'\n",
    "decade.name = 'decade'\n",
    "planets.groupby(['method', decade])['number'].sum().unstack().fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i><font color = \"green\">   unstack() example-\n",
    "  Series with MultiIndex to produce DataFrame. The level involved will automatically get sorted.\n",
    "    </font> </i></h3>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4],\n",
    "index=pd.MultiIndex.from_product([['one', 'two'], ['a', 'b']]))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <font color=\"red\">Example: Random Sampling and Permutation </h1> </font>\n",
    "### Suppose you wanted to draw a random sample (with or without replacement) from a large dataset for some application. There are a number of ways to perform the “draws”; here we use the sample method for Series.\n",
    "### To demonstrate, here’s a way to construct a deck of English-style playing cards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hearts, Spades, Clubs, Diamonds\n",
    "suits = ['H', 'S', 'C', 'D']\n",
    "card_val = (list(range(1, 11)) + [10] * 3) * 4\n",
    "base_names = ['A'] + list(range(2, 11)) + ['J', 'K', 'Q']\n",
    "cards = []\n",
    "for suit in ['H', 'S', 'C', 'D']:\n",
    "    cards.extend(str(num) + suit for num in base_names)\n",
    "\n",
    "deck = pd.Series(card_val, index=cards)\n",
    "#So now we have a Series of length 52 whose index contains card names and values are the ones used in Blackjack \n",
    "#and other games (to keep things simple, just let the ace 'A' be 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing a hand of five cards from the deck could be written as:\n",
    "def draw(deck, n=5):\n",
    "    return deck.sample(n)\n",
    "\n",
    "draw(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose you wanted two random cards from each suit. Because the suit is the last character of each card name, \n",
    "#we can group based on this and use apply:\n",
    "\n",
    "get_suit = lambda card: card[-1] # last letter is suit\n",
    "deck.groupby(get_suit).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, we could write:\n",
    "deck.groupby(get_suit, group_keys=False).apply(draw, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Filling Missing Values with Group-Specific Values\n",
    "When cleaning up missing data, in some cases you will replace data observations using dropna, but in others you may want to impute (fill in) the null (NA) values using a fixed value or some value derived from the data. fillna is the right tool to use; for example, here I fill in NA values with the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(6))\n",
    "s[::2] = np.nan\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.fillna(s.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you need the fill value to vary by group. One way to do this is to group the data and use apply with a function that calls fillna on each data chunk. Here is some sample data on US states divided into eastern and western regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Ohio', 'New York', 'Vermont', 'Florida',\n",
    "             'Oregon', 'Nevada', 'California', 'Idaho']\n",
    "group_key = ['East'] * 4 + ['West'] * 4\n",
    "data = pd.Series(np.random.randn(8), index=states)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the syntax ['East'] * 4 produces a list containing four copies of the elements in ['East']. Adding lists together concatenates them.\n",
    "\n",
    "Let’s set some values in the data to be missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Vermont', 'Nevada', 'Idaho']] = np.nan\n",
    "print(data)\n",
    "data.groupby(group_key).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill the NA values using the group means like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean = lambda g: g.fillna(g.mean())\n",
    "\n",
    "data.groupby(group_key).apply(fill_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another case, you might have predefined fill values in your code that vary by group. Since the groups have a name attribute set internally, we can use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = {'East': 0.5, 'West': -1}\n",
    "fill_func = lambda g: g.fillna(fill_values[g.name])\n",
    "data.groupby(group_key).apply(fill_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
